# !/usr/bin/env python
# -*-coding:utf-8 -*-
# File       : nodes.py
# Time       ï¼š2025/6/30 20:37
# Author     ï¼šaigonna
import os
import json
from loguru import logger
from typing import Annotated, Literal
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage
from langgraph.types import Command, interrupt
from langchain_community.chat_models import ChatLiteLLM
from state import State
from prompts import (PLAN_SYSTEM_PROMPT, PLAN_CREATE_PROMPT,
                     EXECUTE_SYSTEM_PROMPT, EXECUTION_PROMPT, REPORT_SYSTEM_PROMPT)
from tools import (create_file, create_task_folder, send_messages, shell_exec, str_replace,
                   read_csv_data, data_statistics_analysis, create_visualization, trend_analysis,
                   category_analysis, correlation_analysis, outlier_detection, data_export,
                   read_file_content, list_files)
from dotenv import load_dotenv
load_dotenv('.env')

# LLMé…ç½® - ä½¿ç”¨ LiteLLM ç»Ÿä¸€é€‚é…
def get_llm():
    """è·å–LLMå®ä¾‹ï¼Œä½¿ç”¨LiteLLMç»Ÿä¸€é€‚é…å¤šä¸ªæ¨¡å‹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("MODEL_NAME", "gpt-4o")  # é»˜è®¤ä½¿ç”¨gpt-4o
    temperature = float(os.getenv("TEMPERATURE", "0.1"))
    max_tokens = int(os.getenv("MAX_TOKENS", "16384"))
    
    # è®¾ç½®APIå¯†é’¥
    if "gpt" in model_name or "openai" in model_name:
        os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY", os.getenv("openai_key", ""))
        base_url = os.getenv("OPENAI_BASE_URL", os.getenv("openai_base_url"))
        if base_url:
            os.environ["OPENAI_API_BASE"] = base_url
    elif "claude" in model_name:
        os.environ["ANTHROPIC_API_KEY"] = os.getenv("ANTHROPIC_API_KEY", "")
    elif "gemini" in model_name:
        os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY", "")
    elif "deepseek" in model_name:
        os.environ["DEEPSEEK_API_KEY"] = os.getenv("deepseek", "")
        os.environ["DEEPSEEK_API_BASE"] = "https://api.deepseek.com"
    elif "qwen" in model_name:
        os.environ["DASHSCOPE_API_KEY"] = os.getenv("DASHSCOPE_API_KEY", "")
    elif "glm" in model_name:
        os.environ["ZHIPUAI_API_KEY"] = os.getenv("ZHIPUAI_API_KEY", "")
    
    try:
        llm = ChatLiteLLM(
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=60,
            max_retries=3
        )
        logger.info(f"âœ… æˆåŠŸåˆå§‹åŒ–LiteLLMæ¨¡å‹: {model_name}")
        return llm
    except Exception as e:
        logger.error(f"âŒ LiteLLMåˆå§‹åŒ–å¤±è´¥: {e}")
        # é™çº§åˆ°åŸºç¡€OpenAI
        logger.info("ğŸ”„ é™çº§åˆ°åŸºç¡€OpenAIé…ç½®...")
        fallback_llm = ChatLiteLLM(
            model="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=8192
        )
        return fallback_llm

llm = get_llm()

# æ‰“å°å½“å‰é…ç½®
logger.info(f"ğŸ¤– å½“å‰æ¨¡å‹: {os.getenv('MODEL_NAME', 'gpt-4o')}")
logger.info(f"ğŸŒ¡ï¸  æ¸©åº¦è®¾ç½®: {os.getenv('TEMPERATURE', '0.1')}")
logger.info(f"ğŸ“ æœ€å¤§Token: {os.getenv('MAX_TOKENS', '4000')}")
if os.getenv('OPENAI_BASE_URL') or os.getenv('openai_base_url'):
    logger.info(f"ğŸŒ APIåœ°å€: {os.getenv('OPENAI_BASE_URL', os.getenv('openai_base_url'))}")

def extract_json(text):
    if '```json' not in text:
        return text
    text = text.split('```json')[1].split('```')[0].strip()
    return text

def extract_answer(text):
    return text

def create_planner_node(state: State):
    logger.info("***æ­£åœ¨è¿è¡ŒCreate Planner node***")
    
    # Create task folder first if not already created
    if not state.get('task_folder'):
        task_folder_result = create_task_folder.invoke({"user_message": state['user_message']})
        if "task_folder" in task_folder_result:
            task_folder = task_folder_result["task_folder"]
            logger.info(f"Created task folder: {task_folder}")
        else:
            task_folder = ""
            logger.error(f"Failed to create task folder: {task_folder_result}")
    else:
        task_folder = state['task_folder']
    
    messages = [SystemMessage(content=PLAN_SYSTEM_PROMPT), HumanMessage(content=PLAN_CREATE_PROMPT.format(user_message = state['user_message']))]
    response = llm.invoke(messages)
    response = response.model_dump_json(indent=4, exclude_none=True)
    response = json.loads(response)
    plan = json.loads(extract_json(extract_answer(response['content'])))
    state['messages'] += [AIMessage(content=json.dumps(plan, ensure_ascii=False))]
    return Command(goto="execute", update={"plan": plan, "task_folder": task_folder})

def execute_node(state: State):
    logger.info("***æ­£åœ¨è¿è¡Œexecute_node***")
  
    plan = state['plan']
    steps = plan['steps']
    current_step = None
    current_step_index = 0
    
    # è·å–ç¬¬ä¸€ä¸ªæœªå®ŒæˆSTEP
    for i, step in enumerate(steps):
        status = step['status']
        if status == 'pending':
            current_step = step
            current_step_index = i
            break
        
    logger.info(f"å½“å‰æ‰§è¡ŒSTEP:{current_step}")
    
    # å¦‚æœæ²¡æœ‰å¾…æ‰§è¡Œçš„æ­¥éª¤ï¼Œè·³è½¬åˆ°reportèŠ‚ç‚¹
    if current_step is None:
        logger.info("æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œè·³è½¬åˆ°reportèŠ‚ç‚¹")
        return Command(goto='report')
    
    # è¿‡æ»¤æ‰ToolMessageï¼Œåªä¿ç•™SystemMessageã€HumanMessageå’ŒAIMessage
    filtered_observations = [msg for msg in state['observations'] if not isinstance(msg, ToolMessage)]
    messages = filtered_observations + [SystemMessage(content=EXECUTE_SYSTEM_PROMPT), HumanMessage(content=EXECUTION_PROMPT.format(user_message=state['user_message'], step=current_step['description']))]
    
    tool_result = None
    while True:
        # ç»‘å®šæ‰€æœ‰å¯ç”¨å·¥å…·
        available_tools = [
            create_file, str_replace, shell_exec, read_csv_data, data_statistics_analysis,
            create_visualization, trend_analysis, category_analysis, correlation_analysis,
            outlier_detection, data_export, read_file_content, list_files
        ]
        response = llm.bind_tools(available_tools).invoke(messages)
        response = response.model_dump_json(indent=4, exclude_none=True)
        response = json.loads(response)
        
        tools = {
            "create_file": create_file, "str_replace": str_replace, "shell_exec": shell_exec,
            "read_csv_data": read_csv_data, "data_statistics_analysis": data_statistics_analysis,
            "create_visualization": create_visualization, "trend_analysis": trend_analysis,
            "category_analysis": category_analysis, "correlation_analysis": correlation_analysis,
            "outlier_detection": outlier_detection, "data_export": data_export,
            "read_file_content": read_file_content, "list_files": list_files
        }     
        if response['tool_calls']:
            # å…ˆæ·»åŠ AIå“åº”æ¶ˆæ¯
            messages += [AIMessage(content=response['content'], tool_calls=response['tool_calls'])]
            for tool_call in response['tool_calls']:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                
                # Add task_folder to create_file calls
                if tool_name == 'create_file' and state.get('task_folder'):
                    tool_args['task_folder'] = state['task_folder']
                
                tool_result = tools[tool_name].invoke(tool_args)
                logger.info(f"tool_name:{tool_name},tool_args:{tool_args}\ntool_result:{tool_result}")
                messages += [ToolMessage(content=f"tool_name:{tool_name},tool_args:{tool_args}\ntool_result:{tool_result}", tool_call_id=tool_call['id'])]
        
        elif '<tool_call>' in response['content']:
            # æŸäº›æ¨¡å‹ä½¿ç”¨ä¸åŒçš„tool callæ ¼å¼
            logger.info("æ£€æµ‹åˆ°<tool_call>æ ‡ç­¾ï¼Œä½†LiteLLMåº”è¯¥ä½¿ç”¨æ ‡å‡†tool_callsæ ¼å¼")
            break
        else:    
            break
        
    logger.info(f"å½“å‰STEPæ‰§è¡Œæ€»ç»“:{extract_answer(response['content'])}")
    
    # æ ‡è®°å½“å‰æ­¥éª¤ä¸ºå·²å®Œæˆ
    current_step['status'] = 'completed'
    
    state['messages'] += [AIMessage(content=extract_answer(response['content']))]
    # åªæ·»åŠ æ‰§è¡Œæ€»ç»“åˆ°observationsï¼Œä¸æ·»åŠ ToolMessageï¼ˆé¿å…æ ¼å¼é—®é¢˜ï¼‰
    state['observations'] += [AIMessage(content=extract_answer(response['content']))]
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå®Œæˆçš„æ­¥éª¤
    remaining_pending_steps = [step for step in steps if step['status'] == 'pending']
    
    if remaining_pending_steps:
        logger.info(f"è¿˜æœ‰ {len(remaining_pending_steps)} ä¸ªæ­¥éª¤å¾…æ‰§è¡Œï¼Œç»§ç»­æ‰§è¡Œ")
        return Command(goto='execute', update={'plan': plan})
    else:
        logger.info("æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œè·³è½¬åˆ°reportèŠ‚ç‚¹")
        return Command(goto='report', update={'plan': plan})
    

    
def report_node(state: State):
    """Report node that write a final report."""
    logger.info("***æ­£åœ¨è¿è¡Œreport_node***")
    
    observations = state.get("observations")
    # è¿‡æ»¤æ‰ToolMessageï¼Œåªä¿ç•™SystemMessageã€HumanMessageå’ŒAIMessage
    filtered_observations = [msg for msg in observations if not isinstance(msg, ToolMessage)] if observations else []
    messages = filtered_observations + [SystemMessage(content=REPORT_SYSTEM_PROMPT)]
    
    while True:
        # ç»‘å®šæŠ¥å‘Šç”Ÿæˆæ‰€éœ€å·¥å…·
        report_tools = [
            create_file, shell_exec, data_export, read_file_content, list_files
        ]
        response = llm.bind_tools(report_tools).invoke(messages)
        response = response.model_dump_json(indent=4, exclude_none=True)
        response = json.loads(response)
        
        tools = {
            "create_file": create_file, "shell_exec": shell_exec,
            "data_export": data_export, "read_file_content": read_file_content,
            "list_files": list_files
        } 
        if response['tool_calls']:    
            for tool_call in response['tool_calls']:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                
                # Add task_folder to create_file calls
                if tool_name == 'create_file' and state.get('task_folder'):
                    tool_args['task_folder'] = state['task_folder']
                
                tool_result = tools[tool_name].invoke(tool_args)
                logger.info(f"tool_name:{tool_name},tool_args:{tool_args}\ntool_result:{tool_result}")
                messages += [ToolMessage(content=f"tool_name:{tool_name},tool_args:{tool_args}\ntool_result:{tool_result}", tool_call_id=tool_call['id'])]
        else:
            break
            
    logger.info("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    return {"final_report": response['content']}